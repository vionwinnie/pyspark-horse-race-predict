{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an improved kernel on [previous one](https://www.kaggle.com/cullensun/deep-learning-model-for-horse-racing). In previous kernel, I tried to predict on every single horse run. However, I found it makes more sense to predict winner horse for every race because winning is **relative** to other horses performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages\n",
    "Here, we import common packages for deep learning. \n",
    "- pandas: for data reading and preprocessing\n",
    "- tensorflow: for neural network construction \n",
    "- sklearn.preprocessing: for data encoding\n",
    "- sklearn.model_selection: it has convenient method for training/test data spliting \n",
    "- matplotlib.pyplot: to plot performance of the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.model_selection as model_selection\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare races data from races.csv\n",
    "Only select several columns that make sense for this kernel. Then, use different encoders for different types of attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [venue, config, surface, distance, going, race_class]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "races_df = pd.read_csv(r\"races.csv\", delimiter=\",\", header=0, index_col='race_id')\n",
    "races_df = races_df[['venue', 'config', 'surface', 'distance', 'going', 'race_class']]\n",
    "\n",
    "# check to see if we have NaN, then drop NaN\n",
    "print(races_df[races_df.isnull().any(axis=1)])\n",
    "races_df = races_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "venue           int64\n",
      "config        float64\n",
      "surface         int64\n",
      "distance        int64\n",
      "going         float64\n",
      "race_class      int64\n",
      "dtype: object\n",
      "(6349, 6)\n",
      "         venue  config  surface  distance  going  race_class\n",
      "race_id                                                     \n",
      "0            1     0.0        0      1400    2.0           5\n",
      "1            1     0.0        0      1200    2.0           5\n",
      "2            1     0.0        0      1400    2.0           4\n",
      "3            1     0.0        0      1200    2.0           1\n",
      "4            1     0.0        0      1600    2.0           4\n"
     ]
    }
   ],
   "source": [
    "# encode ordinal columns: config, going, \n",
    "config_encoder = preprocessing.OrdinalEncoder()\n",
    "races_df['config'] = config_encoder.fit_transform(races_df['config'].values.reshape(-1, 1))\n",
    "going_encoder = preprocessing.OrdinalEncoder()\n",
    "races_df['going'] = going_encoder.fit_transform(races_df['going'].values.reshape(-1, 1))\n",
    "\n",
    "# encode nominal column: venue\n",
    "venue_encoder = preprocessing.LabelEncoder()\n",
    "races_df['venue'] = venue_encoder.fit_transform(races_df['venue'])\n",
    "\n",
    "print(races_df.dtypes)\n",
    "print(races_df.shape)\n",
    "print(races_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare races data from runs.csv\n",
    "Similar to races data, only select columns that are relevant to the model. \n",
    "\n",
    "### Data cleaning\n",
    "- two rows that includes NaN, so just drop them.\n",
    "- strange data for 'draw', e.g. 15. As we only deal with standard 14 horses racing, so let's drop it.\n",
    "\n",
    "### Encoding \n",
    "Then, use label encoders for 'horse_country' and 'horse_type'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     race_id  draw  horse_age horse_country horse_type  horse_rating  \\\n",
      "182       13    12          3           NaN        NaN            60   \n",
      "846       69     1          3           NaN        NaN            60   \n",
      "\n",
      "     declared_weight  actual_weight  win_odds  result  \n",
      "182           1107.0            120      28.0       5  \n",
      "846           1105.0            119      14.0      11  \n",
      "race_id              int64\n",
      "draw                 int64\n",
      "horse_age            int64\n",
      "horse_country        int64\n",
      "horse_type           int64\n",
      "horse_rating         int64\n",
      "declared_weight    float64\n",
      "actual_weight        int64\n",
      "win_odds           float64\n",
      "result               int64\n",
      "dtype: object\n",
      "(79444, 10)\n",
      "   race_id  draw  horse_age  horse_country  horse_type  horse_rating  \\\n",
      "0        0     7          3              1           3            60   \n",
      "1        0    12          3             11           3            60   \n",
      "2        0     8          3             11           3            60   \n",
      "3        0    13          3             12           3            60   \n",
      "4        0    14          3              5           3            60   \n",
      "\n",
      "   declared_weight  actual_weight  win_odds  result  \n",
      "0           1020.0            133       9.7      10  \n",
      "1            980.0            133      16.0       8  \n",
      "2           1082.0            132       3.5       7  \n",
      "3           1118.0            127      39.0       9  \n",
      "4            972.0            131      50.0       6  \n"
     ]
    }
   ],
   "source": [
    "runs_df = pd.read_csv(r\"runs.csv\", delimiter=\",\", header=0)\n",
    "runs_df = runs_df[['race_id', 'draw', \n",
    "                   'horse_age', 'horse_country', 'horse_type', 'horse_rating', 'declared_weight', 'actual_weight', 'win_odds', \n",
    "                   'result']] \n",
    "\n",
    "# check to see if we have NaN, then drop NaN\n",
    "print(runs_df[runs_df.isnull().any(axis=1)])\n",
    "runs_df = runs_df.dropna()\n",
    "\n",
    "# not sure why, but we got some strange draw in the dataset. Maximum shall be 14\n",
    "strange_draw_index = runs_df[runs_df['draw'] > 14].index\n",
    "# delete these row indexes from dataFrame\n",
    "runs_df = runs_df.drop(strange_draw_index)\n",
    "\n",
    "# encode nominal columns: horse_country, horse_type\n",
    "horse_country_encoder = preprocessing.LabelEncoder()\n",
    "runs_df['horse_country'] = horse_country_encoder.fit_transform(runs_df['horse_country'])\n",
    "horse_type_encoder = preprocessing.LabelEncoder()\n",
    "runs_df['horse_type'] = horse_type_encoder.fit_transform(runs_df['horse_type'])\n",
    "\n",
    "print(runs_df.dtypes)\n",
    "print(runs_df.shape)\n",
    "print(runs_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further preprocessing for runs data\n",
    "We are targeting to put all the 14 horses' features into the one input, but it expands into multiple rows now. Luckily, pandas has a nice method called `pivot`. `pivot` aggregates horses data from multiple rows, which belongs to a single race, into one row. \n",
    "\n",
    "After `pivot`, some races may not have 14 horses, so let's fill NaN with 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        horse_age horse_country horse_type horse_rating declared_weight  \\\n",
      "draw           1             1          1            1               1    \n",
      "race_id                                                                   \n",
      "0             3.0          14.0        3.0         60.0          1089.0   \n",
      "1             3.0           1.0        3.0         60.0          1059.0   \n",
      "2             3.0           1.0        3.0         60.0          1028.0   \n",
      "3             3.0          14.0        5.0         60.0          1074.0   \n",
      "4             3.0          11.0        3.0         60.0           988.0   \n",
      "\n",
      "        actual_weight win_odds horse_age horse_country horse_type  ... result  \\\n",
      "draw               1        1         2             2          2   ...     5    \n",
      "race_id                                                            ...          \n",
      "0               120.0      5.4       3.0           1.0        3.0  ...    3.0   \n",
      "1               121.0     10.0       3.0          11.0        3.0  ...    8.0   \n",
      "2               116.0     45.0       3.0          11.0        3.0  ...   14.0   \n",
      "3               115.0      2.9       3.0          11.0        3.0  ...    3.0   \n",
      "4               106.0     31.0       3.0          11.0        3.0  ...   14.0   \n",
      "\n",
      "                                                               \n",
      "draw       6     7     8     9     10    11    12    13    14  \n",
      "race_id                                                        \n",
      "0        13.0  10.0   7.0  14.0   4.0  12.0   8.0   9.0   6.0  \n",
      "1         2.0   5.0  10.0  12.0   1.0   3.0   9.0  14.0  13.0  \n",
      "2         6.0   4.0   7.0   9.0  10.0   5.0  11.0   3.0  12.0  \n",
      "3        11.0   8.0   9.0   6.0  12.0   2.0  10.0   NaN   NaN  \n",
      "4         6.0   2.0   8.0  10.0  13.0   7.0   4.0  11.0  12.0  \n",
      "\n",
      "[5 rows x 112 columns]\n"
     ]
    }
   ],
   "source": [
    "def group_horse_and_result(element):\n",
    "    if element[0] == 'result':\n",
    "        return 100 + element[1] # to make sure results are put near the end\n",
    "    else:\n",
    "        return element[1]   \n",
    "\n",
    "runs_df = runs_df.pivot(index='race_id', columns='draw', values=runs_df.columns[2:])\n",
    "rearranged_columns = sorted(list(runs_df.columns.values), key=group_horse_and_result)\n",
    "runs_df = runs_df[rearranged_columns]\n",
    "print(runs_df.head())\n",
    "\n",
    "# quite some NaNs appreared in the dataframe, reason is some races didnt have full 14 horses participating\n",
    "# fill with 0\n",
    "runs_df = runs_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horse_age 1\n",
      "horse_country 1\n",
      "horse_type 1\n",
      "horse_rating 1\n",
      "declared_weight 1\n",
      "actual_weight 1\n",
      "win_odds 1\n",
      "horse_age 2\n",
      "horse_country 2\n",
      "horse_type 2\n",
      "horse_rating 2\n",
      "declared_weight 2\n",
      "actual_weight 2\n",
      "win_odds 2\n",
      "horse_age 3\n",
      "horse_country 3\n",
      "horse_type 3\n",
      "horse_rating 3\n",
      "declared_weight 3\n",
      "actual_weight 3\n",
      "win_odds 3\n",
      "horse_age 4\n",
      "horse_country 4\n",
      "horse_type 4\n",
      "horse_rating 4\n",
      "declared_weight 4\n",
      "actual_weight 4\n",
      "win_odds 4\n",
      "horse_age 5\n",
      "horse_country 5\n",
      "horse_type 5\n",
      "horse_rating 5\n",
      "declared_weight 5\n",
      "actual_weight 5\n",
      "win_odds 5\n",
      "horse_age 6\n",
      "horse_country 6\n",
      "horse_type 6\n",
      "horse_rating 6\n",
      "declared_weight 6\n",
      "actual_weight 6\n",
      "win_odds 6\n",
      "horse_age 7\n",
      "horse_country 7\n",
      "horse_type 7\n",
      "horse_rating 7\n",
      "declared_weight 7\n",
      "actual_weight 7\n",
      "win_odds 7\n",
      "horse_age 8\n",
      "horse_country 8\n",
      "horse_type 8\n",
      "horse_rating 8\n",
      "declared_weight 8\n",
      "actual_weight 8\n",
      "win_odds 8\n",
      "horse_age 9\n",
      "horse_country 9\n",
      "horse_type 9\n",
      "horse_rating 9\n",
      "declared_weight 9\n",
      "actual_weight 9\n",
      "win_odds 9\n",
      "horse_age 10\n",
      "horse_country 10\n",
      "horse_type 10\n",
      "horse_rating 10\n",
      "declared_weight 10\n",
      "actual_weight 10\n",
      "win_odds 10\n",
      "horse_age 11\n",
      "horse_country 11\n",
      "horse_type 11\n",
      "horse_rating 11\n",
      "declared_weight 11\n",
      "actual_weight 11\n",
      "win_odds 11\n",
      "horse_age 12\n",
      "horse_country 12\n",
      "horse_type 12\n",
      "horse_rating 12\n",
      "declared_weight 12\n",
      "actual_weight 12\n",
      "win_odds 12\n",
      "horse_age 13\n",
      "horse_country 13\n",
      "horse_type 13\n",
      "horse_rating 13\n",
      "declared_weight 13\n",
      "actual_weight 13\n",
      "win_odds 13\n",
      "horse_age 14\n",
      "horse_country 14\n",
      "horse_type 14\n",
      "horse_rating 14\n",
      "declared_weight 14\n",
      "actual_weight 14\n",
      "win_odds 14\n",
      "result 1\n",
      "result 2\n",
      "result 3\n",
      "result 4\n",
      "result 5\n",
      "result 6\n",
      "result 7\n",
      "result 8\n",
      "result 9\n",
      "result 10\n",
      "result 11\n",
      "result 12\n",
      "result 13\n",
      "result 14\n"
     ]
    }
   ],
   "source": [
    "for cur in runs_df.columns:\n",
    "    print(cur[0],cur[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare training/test data \n",
    "Here, we combine races data and runs data by `join` two data frames above. \n",
    "\n",
    "### Standardization\n",
    "If you look at the data closely, if will find that features are not in the same scale, e.g. weight can go to 1000+. Standardize the data for to make training easier. \n",
    "\n",
    "### Select right columns for X, y\n",
    "- Select all the data except last 28 columns, because last 28 columns is about 'result' and 'won'\n",
    "- Select last 14 columns for y_won. Each row shall have one '1.0' and rest are 0. \n",
    "- Select second last 14 columns for y_top3. It used to the the column 'result', e.g. 1~14, which is horses' final positions when the race finishes. Apply a function to convert it to 1.0 if the horse is in top 3, else 0. \n",
    "\n",
    "### Split data into train/test sets\n",
    "\n",
    "sklearn comes with such a handy method `train_test_split`. We split the data as following:\n",
    "- 80% for training\n",
    "- 20% for testing(validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/winnie/developer/conda_env/ml-toolbox/lib/python3.7/site-packages/pandas/core/reshape/merge.py:618: UserWarning: merging between different levels can give an unintended result (1 levels on the left, 2 on the right)\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6348, 104)\n",
      "(6348, 14)\n",
      "X_train (5078, 104)\n",
      "y_train (5078, 14)\n",
      "X_test (1270, 104)\n",
      "y_test (1270, 14)\n"
     ]
    }
   ],
   "source": [
    "data = races_df.join(runs_df, on='race_id', how='right')\n",
    "X = data[data.columns[:-14]] \n",
    "ss = preprocessing.StandardScaler()\n",
    "X = pd.DataFrame(ss.fit_transform(X),columns = X.columns)\n",
    "\n",
    "y_won = data[data.columns[-14:]].applymap(lambda x: 1.0 if 0.5 < x < 1.5 else 0.0) \n",
    "\n",
    "print(X.shape)\n",
    "print(y_won.shape)\n",
    "\n",
    "# split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y_won, train_size=0.8, test_size=0.2, random_state=1)\n",
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                'venue',                'config',\n",
       "                     'surface',              'distance',\n",
       "                       'going',            'race_class',\n",
       "              ('horse_age', 1),    ('horse_country', 1),\n",
       "             ('horse_type', 1),     ('horse_rating', 1),\n",
       "       ...\n",
       "       ('declared_weight', 13),   ('actual_weight', 13),\n",
       "              ('win_odds', 13),       ('horse_age', 14),\n",
       "         ('horse_country', 14),      ('horse_type', 14),\n",
       "          ('horse_rating', 14), ('declared_weight', 14),\n",
       "         ('actual_weight', 14),        ('win_odds', 14)],\n",
       "      dtype='object', length=104)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(result, 1)</th>\n",
       "      <th>(result, 2)</th>\n",
       "      <th>(result, 3)</th>\n",
       "      <th>(result, 4)</th>\n",
       "      <th>(result, 5)</th>\n",
       "      <th>(result, 6)</th>\n",
       "      <th>(result, 7)</th>\n",
       "      <th>(result, 8)</th>\n",
       "      <th>(result, 9)</th>\n",
       "      <th>(result, 10)</th>\n",
       "      <th>(result, 11)</th>\n",
       "      <th>(result, 12)</th>\n",
       "      <th>(result, 13)</th>\n",
       "      <th>(result, 14)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>race_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         (result, 1)  (result, 2)  (result, 3)  (result, 4)  (result, 5)  \\\n",
       "race_id                                                                    \n",
       "0               11.0          1.0          2.0          5.0          3.0   \n",
       "1                4.0         11.0          7.0          6.0          8.0   \n",
       "2               13.0          2.0          8.0          1.0         14.0   \n",
       "3                7.0          4.0          5.0          1.0          3.0   \n",
       "4                9.0          5.0          1.0          3.0         14.0   \n",
       "\n",
       "         (result, 6)  (result, 7)  (result, 8)  (result, 9)  (result, 10)  \\\n",
       "race_id                                                                     \n",
       "0               13.0         10.0          7.0         14.0           4.0   \n",
       "1                2.0          5.0         10.0         12.0           1.0   \n",
       "2                6.0          4.0          7.0          9.0          10.0   \n",
       "3               11.0          8.0          9.0          6.0          12.0   \n",
       "4                6.0          2.0          8.0         10.0          13.0   \n",
       "\n",
       "         (result, 11)  (result, 12)  (result, 13)  (result, 14)  \n",
       "race_id                                                          \n",
       "0                12.0           8.0           9.0           6.0  \n",
       "1                 3.0           9.0          14.0          13.0  \n",
       "2                 5.0          11.0           3.0          12.0  \n",
       "3                 2.0          10.0           0.0           0.0  \n",
       "4                 7.0           4.0          11.0          12.0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:,-14:].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the model\n",
    "\n",
    "Use keras to build the model with easy-to-use api `Sequential`. \n",
    "\n",
    "Have to mention that input layer has 104 inputs. The calculation is following:\n",
    "- 6 features from races dataframe: 'venue', 'config', 'surface', 'distance', 'going', 'race_class'\n",
    "- 14 horses per races, and each horse has 7 features; 'horse_age', 'horse_country', 'horse_type', 'horse_rating', 'declared_weight', 'actual_weight', 'win_odds'\n",
    "- so total 104 features = 6 + 14 x 7\n",
    "\n",
    "\n",
    "Output layer has 14 nodes, as each node stands for each horse's result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(96, activation='relu', input_shape=(104,)),\n",
    "    tf.keras.layers.Dense(14, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(5e-04),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              metrics=[tf.keras.metrics.Precision(name='precision')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training..\n",
      "\n",
      "Train for 11 steps, validate for 3 steps\n",
      "Epoch 1/200\n",
      "11/11 [==============================] - 1s 56ms/step - loss: 2.9226 - precision: 0.0709 - val_loss: 2.8180 - val_precision: 0.0000e+00\n",
      "Epoch 2/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.7859 - precision: 0.0690 - val_loss: 2.7430 - val_precision: 0.0714\n",
      "Epoch 3/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.7040 - precision: 0.0833 - val_loss: 2.6858 - val_precision: 0.1667\n",
      "Epoch 4/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.6472 - precision: 0.1111 - val_loss: 2.6486 - val_precision: 0.2000\n",
      "Epoch 5/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.6007 - precision: 0.0909 - val_loss: 2.6248 - val_precision: 0.3333\n",
      "Epoch 6/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.5633 - precision: 0.2000 - val_loss: 2.6067 - val_precision: 0.5000\n",
      "Epoch 7/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.5277 - precision: 0.2500 - val_loss: 2.5937 - val_precision: 0.0000e+00\n",
      "Epoch 8/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.4989 - precision: 0.5000 - val_loss: 2.5703 - val_precision: 0.0000e+00\n",
      "Epoch 9/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.4822 - precision: 0.6000 - val_loss: 2.5633 - val_precision: 0.0000e+00\n",
      "Epoch 10/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.4599 - precision: 0.7500 - val_loss: 2.5410 - val_precision: 0.0000e+00\n",
      "Epoch 11/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.4281 - precision: 1.0000 - val_loss: 2.5384 - val_precision: 0.0000e+00\n",
      "Epoch 12/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.4153 - precision: 1.0000 - val_loss: 2.5375 - val_precision: 0.0000e+00\n",
      "Epoch 13/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.3878 - precision: 1.0000 - val_loss: 2.5184 - val_precision: 0.0000e+00\n",
      "Epoch 14/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.3782 - precision: 1.0000 - val_loss: 2.5165 - val_precision: 0.0000e+00\n",
      "Epoch 15/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.3573 - precision: 0.3333 - val_loss: 2.5087 - val_precision: 0.0000e+00\n",
      "Epoch 16/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.3424 - precision: 0.6667 - val_loss: 2.5018 - val_precision: 0.0000e+00\n",
      "Epoch 17/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.3333 - precision: 0.6667 - val_loss: 2.4956 - val_precision: 0.0000e+00\n",
      "Epoch 18/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.3124 - precision: 0.6667 - val_loss: 2.4814 - val_precision: 0.0000e+00\n",
      "Epoch 19/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2933 - precision: 1.0000 - val_loss: 2.4839 - val_precision: 0.0000e+00\n",
      "Epoch 20/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2789 - precision: 1.0000 - val_loss: 2.4798 - val_precision: 0.0000e+00\n",
      "Epoch 21/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2679 - precision: 1.0000 - val_loss: 2.4692 - val_precision: 0.0000e+00\n",
      "Epoch 22/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2541 - precision: 1.0000 - val_loss: 2.4592 - val_precision: 0.0000e+00\n",
      "Epoch 23/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2365 - precision: 0.8333 - val_loss: 2.4601 - val_precision: 0.0000e+00\n",
      "Epoch 24/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2308 - precision: 0.8333 - val_loss: 2.4616 - val_precision: 0.0000e+00\n",
      "Epoch 25/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2283 - precision: 0.8571 - val_loss: 2.4652 - val_precision: 0.0000e+00\n",
      "Epoch 26/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.2122 - precision: 0.8889 - val_loss: 2.4551 - val_precision: 0.0000e+00\n",
      "Epoch 27/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1967 - precision: 0.7857 - val_loss: 2.4376 - val_precision: 0.0000e+00\n",
      "Epoch 28/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1890 - precision: 0.9231 - val_loss: 2.4444 - val_precision: 0.0000e+00\n",
      "Epoch 29/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1802 - precision: 0.8667 - val_loss: 2.4498 - val_precision: 0.0000e+00\n",
      "Epoch 30/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1665 - precision: 0.8750 - val_loss: 2.4323 - val_precision: 0.0000e+00\n",
      "Epoch 31/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1626 - precision: 0.8500 - val_loss: 2.4408 - val_precision: 0.2000\n",
      "Epoch 32/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1542 - precision: 0.8000 - val_loss: 2.4389 - val_precision: 0.1667\n",
      "Epoch 33/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1353 - precision: 0.7391 - val_loss: 2.4384 - val_precision: 0.2000\n",
      "Epoch 34/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1320 - precision: 0.8182 - val_loss: 2.4398 - val_precision: 0.2500\n",
      "Epoch 35/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1260 - precision: 0.9091 - val_loss: 2.4327 - val_precision: 0.2500\n",
      "Epoch 36/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1073 - precision: 0.9130 - val_loss: 2.4215 - val_precision: 0.2000\n",
      "Epoch 37/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.1141 - precision: 0.9231 - val_loss: 2.4416 - val_precision: 0.2000\n",
      "Epoch 38/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0965 - precision: 0.9286 - val_loss: 2.4226 - val_precision: 0.2000\n",
      "Epoch 39/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0885 - precision: 0.9286 - val_loss: 2.4260 - val_precision: 0.1667\n",
      "Epoch 40/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0766 - precision: 0.9062 - val_loss: 2.4246 - val_precision: 0.1667\n",
      "Epoch 41/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 2.0679 - precision: 0.8788 - val_loss: 2.4335 - val_precision: 0.1667\n",
      "Epoch 42/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0598 - precision: 0.8611 - val_loss: 2.4181 - val_precision: 0.1250\n",
      "Epoch 43/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0522 - precision: 0.8889 - val_loss: 2.4231 - val_precision: 0.1429\n",
      "Epoch 44/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0488 - precision: 0.9189 - val_loss: 2.4296 - val_precision: 0.1667\n",
      "Epoch 45/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0401 - precision: 0.9024 - val_loss: 2.4241 - val_precision: 0.1250\n",
      "Epoch 46/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0281 - precision: 0.9111 - val_loss: 2.4253 - val_precision: 0.1250\n",
      "Epoch 47/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0277 - precision: 0.8800 - val_loss: 2.4211 - val_precision: 0.1429\n",
      "Epoch 48/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0101 - precision: 0.9167 - val_loss: 2.4178 - val_precision: 0.1429\n",
      "Epoch 49/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 2.0048 - precision: 0.9259 - val_loss: 2.4228 - val_precision: 0.2000\n",
      "Epoch 50/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9949 - precision: 0.8852 - val_loss: 2.4105 - val_precision: 0.2000\n",
      "Epoch 51/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9922 - precision: 0.8852 - val_loss: 2.4222 - val_precision: 0.2308\n",
      "Epoch 52/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9908 - precision: 0.8971 - val_loss: 2.4138 - val_precision: 0.2500\n",
      "Epoch 53/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9785 - precision: 0.9067 - val_loss: 2.4223 - val_precision: 0.2857\n",
      "Epoch 54/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9684 - precision: 0.9125 - val_loss: 2.4062 - val_precision: 0.2308\n",
      "Epoch 55/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.9662 - precision: 0.9079 - val_loss: 2.4270 - val_precision: 0.2000\n",
      "Epoch 56/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9564 - precision: 0.9070 - val_loss: 2.4205 - val_precision: 0.1875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9518 - precision: 0.9126 - val_loss: 2.4193 - val_precision: 0.2778\n",
      "Epoch 58/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9498 - precision: 0.9175 - val_loss: 2.4240 - val_precision: 0.2500\n",
      "Epoch 59/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9435 - precision: 0.9082 - val_loss: 2.4255 - val_precision: 0.2727\n",
      "Epoch 60/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9255 - precision: 0.9118 - val_loss: 2.4212 - val_precision: 0.1905\n",
      "Epoch 61/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9256 - precision: 0.9123 - val_loss: 2.4178 - val_precision: 0.2222\n",
      "Epoch 62/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9190 - precision: 0.8992 - val_loss: 2.4150 - val_precision: 0.2727\n",
      "Epoch 63/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9098 - precision: 0.9055 - val_loss: 2.4261 - val_precision: 0.2917\n",
      "Epoch 64/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9058 - precision: 0.9120 - val_loss: 2.4275 - val_precision: 0.2381\n",
      "Epoch 65/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9036 - precision: 0.9291 - val_loss: 2.4259 - val_precision: 0.3043\n",
      "Epoch 66/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8951 - precision: 0.9124 - val_loss: 2.4237 - val_precision: 0.3333\n",
      "Epoch 67/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.9001 - precision: 0.8944 - val_loss: 2.4410 - val_precision: 0.2414\n",
      "Epoch 68/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8952 - precision: 0.9085 - val_loss: 2.4310 - val_precision: 0.2647\n",
      "Epoch 69/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8846 - precision: 0.9097 - val_loss: 2.4418 - val_precision: 0.2500\n",
      "Epoch 70/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8672 - precision: 0.9145 - val_loss: 2.4366 - val_precision: 0.2500\n",
      "Epoch 71/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8661 - precision: 0.8839 - val_loss: 2.4331 - val_precision: 0.2941\n",
      "Epoch 72/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8605 - precision: 0.8848 - val_loss: 2.4396 - val_precision: 0.2857\n",
      "Epoch 73/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8623 - precision: 0.9000 - val_loss: 2.4479 - val_precision: 0.2973\n",
      "Epoch 74/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8575 - precision: 0.9034 - val_loss: 2.4401 - val_precision: 0.2703\n",
      "Epoch 75/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8520 - precision: 0.9010 - val_loss: 2.4288 - val_precision: 0.2821\n",
      "Epoch 76/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8450 - precision: 0.8883 - val_loss: 2.4411 - val_precision: 0.2895\n",
      "Epoch 77/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8326 - precision: 0.8812 - val_loss: 2.4432 - val_precision: 0.2895\n",
      "Epoch 78/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8368 - precision: 0.8867 - val_loss: 2.4417 - val_precision: 0.3333\n",
      "Epoch 79/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8344 - precision: 0.8952 - val_loss: 2.4475 - val_precision: 0.3095\n",
      "Epoch 80/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8209 - precision: 0.8920 - val_loss: 2.4453 - val_precision: 0.2857\n",
      "Epoch 81/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8123 - precision: 0.8982 - val_loss: 2.4635 - val_precision: 0.2727\n",
      "Epoch 82/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8121 - precision: 0.8874 - val_loss: 2.4456 - val_precision: 0.2667\n",
      "Epoch 83/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8050 - precision: 0.8966 - val_loss: 2.4430 - val_precision: 0.2826\n",
      "Epoch 84/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.8060 - precision: 0.8958 - val_loss: 2.4565 - val_precision: 0.2826\n",
      "Epoch 85/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7909 - precision: 0.8911 - val_loss: 2.4511 - val_precision: 0.2653\n",
      "Epoch 86/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7896 - precision: 0.8845 - val_loss: 2.4525 - val_precision: 0.2593\n",
      "Epoch 87/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7896 - precision: 0.8973 - val_loss: 2.4501 - val_precision: 0.2545\n",
      "Epoch 88/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7855 - precision: 0.9094 - val_loss: 2.4616 - val_precision: 0.2321\n",
      "Epoch 89/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7702 - precision: 0.9011 - val_loss: 2.4653 - val_precision: 0.2632\n",
      "Epoch 90/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7737 - precision: 0.8993 - val_loss: 2.4662 - val_precision: 0.2456\n",
      "Epoch 91/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7717 - precision: 0.9024 - val_loss: 2.4622 - val_precision: 0.2258\n",
      "Epoch 92/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7646 - precision: 0.9079 - val_loss: 2.4590 - val_precision: 0.2295\n",
      "Epoch 93/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7554 - precision: 0.9088 - val_loss: 2.4860 - val_precision: 0.2154\n",
      "Epoch 94/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7530 - precision: 0.8975 - val_loss: 2.4827 - val_precision: 0.2154\n",
      "Epoch 95/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7605 - precision: 0.8957 - val_loss: 2.4703 - val_precision: 0.2188\n",
      "Epoch 96/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.7542 - precision: 0.8957 - val_loss: 2.4770 - val_precision: 0.2121\n",
      "Epoch 97/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7477 - precision: 0.8932 - val_loss: 2.4638 - val_precision: 0.2174\n",
      "Epoch 98/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7428 - precision: 0.9053 - val_loss: 2.4639 - val_precision: 0.2308\n",
      "Epoch 99/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7251 - precision: 0.9000 - val_loss: 2.4795 - val_precision: 0.2429\n",
      "Epoch 100/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7229 - precision: 0.9086 - val_loss: 2.4934 - val_precision: 0.2237\n",
      "Epoch 101/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7239 - precision: 0.8910 - val_loss: 2.4944 - val_precision: 0.2267\n",
      "Epoch 102/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7145 - precision: 0.8858 - val_loss: 2.4827 - val_precision: 0.2055\n",
      "Epoch 103/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7092 - precision: 0.8877 - val_loss: 2.4859 - val_precision: 0.2133\n",
      "Epoch 104/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7239 - precision: 0.8911 - val_loss: 2.4809 - val_precision: 0.2308\n",
      "Epoch 105/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7177 - precision: 0.8972 - val_loss: 2.4920 - val_precision: 0.2179\n",
      "Epoch 106/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7014 - precision: 0.8889 - val_loss: 2.4881 - val_precision: 0.2195\n",
      "Epoch 107/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6837 - precision: 0.8963 - val_loss: 2.5082 - val_precision: 0.2099\n",
      "Epoch 108/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.7062 - precision: 0.8886 - val_loss: 2.5064 - val_precision: 0.2346\n",
      "Epoch 109/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6779 - precision: 0.8914 - val_loss: 2.5082 - val_precision: 0.2195\n",
      "Epoch 110/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6816 - precision: 0.8986 - val_loss: 2.5021 - val_precision: 0.1860\n",
      "Epoch 111/200\n",
      "11/11 [==============================] - ETA: 0s - loss: 1.6228 - precision: 0.866 - 0s 6ms/step - loss: 1.6864 - precision: 0.8984 - val_loss: 2.5008 - val_precision: 0.2069\n",
      "Epoch 112/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6810 - precision: 0.9085 - val_loss: 2.5089 - val_precision: 0.2159\n",
      "Epoch 113/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6829 - precision: 0.9020 - val_loss: 2.5373 - val_precision: 0.2299\n",
      "Epoch 114/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6697 - precision: 0.8887 - val_loss: 2.5185 - val_precision: 0.2065\n",
      "Epoch 115/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6743 - precision: 0.8988 - val_loss: 2.5234 - val_precision: 0.2178\n",
      "Epoch 116/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6595 - precision: 0.9032 - val_loss: 2.5241 - val_precision: 0.2062\n",
      "Epoch 117/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6585 - precision: 0.8887 - val_loss: 2.5201 - val_precision: 0.2039\n",
      "Epoch 118/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6671 - precision: 0.8957 - val_loss: 2.5092 - val_precision: 0.1961\n",
      "Epoch 119/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6500 - precision: 0.9002 - val_loss: 2.5261 - val_precision: 0.2000\n",
      "Epoch 120/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6478 - precision: 0.9075 - val_loss: 2.5122 - val_precision: 0.2000\n",
      "Epoch 121/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6401 - precision: 0.9081 - val_loss: 2.5174 - val_precision: 0.1869\n",
      "Epoch 122/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6358 - precision: 0.8987 - val_loss: 2.5262 - val_precision: 0.2018\n",
      "Epoch 123/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6312 - precision: 0.9031 - val_loss: 2.5149 - val_precision: 0.1923\n",
      "Epoch 124/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6281 - precision: 0.8921 - val_loss: 2.5285 - val_precision: 0.2039\n",
      "Epoch 125/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6374 - precision: 0.8893 - val_loss: 2.5303 - val_precision: 0.2095\n",
      "Epoch 126/200\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.6295 - precision: 0.8908 - val_loss: 2.5407 - val_precision: 0.2000\n",
      "Epoch 127/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6088 - precision: 0.9010 - val_loss: 2.5142 - val_precision: 0.2000\n",
      "Epoch 128/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6129 - precision: 0.9092 - val_loss: 2.5550 - val_precision: 0.1880\n",
      "Epoch 129/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6269 - precision: 0.9139 - val_loss: 2.5387 - val_precision: 0.1880\n",
      "Epoch 130/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6099 - precision: 0.9069 - val_loss: 2.5516 - val_precision: 0.2000\n",
      "Epoch 131/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5965 - precision: 0.8958 - val_loss: 2.5491 - val_precision: 0.2033\n",
      "Epoch 132/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5962 - precision: 0.9031 - val_loss: 2.5505 - val_precision: 0.1951\n",
      "Epoch 133/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5925 - precision: 0.9045 - val_loss: 2.5453 - val_precision: 0.2034\n",
      "Epoch 134/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.6007 - precision: 0.9006 - val_loss: 2.5405 - val_precision: 0.2185\n",
      "Epoch 135/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5950 - precision: 0.9020 - val_loss: 2.5645 - val_precision: 0.2149\n",
      "Epoch 136/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5907 - precision: 0.8984 - val_loss: 2.5783 - val_precision: 0.2080\n",
      "Epoch 137/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5871 - precision: 0.8978 - val_loss: 2.5602 - val_precision: 0.2266\n",
      "Epoch 138/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5698 - precision: 0.8970 - val_loss: 2.5568 - val_precision: 0.2074\n",
      "Epoch 139/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5700 - precision: 0.9016 - val_loss: 2.5720 - val_precision: 0.2000\n",
      "Epoch 140/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5644 - precision: 0.8988 - val_loss: 2.5782 - val_precision: 0.2074\n",
      "Epoch 141/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5712 - precision: 0.8993 - val_loss: 2.5718 - val_precision: 0.2158\n",
      "Epoch 142/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5606 - precision: 0.9051 - val_loss: 2.5902 - val_precision: 0.2308\n",
      "Epoch 143/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5667 - precision: 0.9060 - val_loss: 2.5794 - val_precision: 0.2256\n",
      "Epoch 144/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5578 - precision: 0.9047 - val_loss: 2.5792 - val_precision: 0.2230\n",
      "Epoch 145/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5462 - precision: 0.9031 - val_loss: 2.5599 - val_precision: 0.2098\n",
      "Epoch 146/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5567 - precision: 0.9012 - val_loss: 2.5863 - val_precision: 0.2128\n",
      "Epoch 147/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5465 - precision: 0.8905 - val_loss: 2.5878 - val_precision: 0.2095\n",
      "Epoch 148/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5352 - precision: 0.9060 - val_loss: 2.5848 - val_precision: 0.2171\n",
      "Epoch 149/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5338 - precision: 0.9070 - val_loss: 2.5848 - val_precision: 0.2179\n",
      "Epoch 150/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5291 - precision: 0.9059 - val_loss: 2.5881 - val_precision: 0.2188\n",
      "Epoch 151/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5282 - precision: 0.9085 - val_loss: 2.5943 - val_precision: 0.2201\n",
      "Epoch 152/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5383 - precision: 0.9050 - val_loss: 2.5888 - val_precision: 0.2375\n",
      "Epoch 153/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5288 - precision: 0.9090 - val_loss: 2.6177 - val_precision: 0.2235\n",
      "Epoch 154/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5330 - precision: 0.9077 - val_loss: 2.5950 - val_precision: 0.2250\n",
      "Epoch 155/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5144 - precision: 0.9018 - val_loss: 2.6085 - val_precision: 0.2250\n",
      "Epoch 156/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5119 - precision: 0.9061 - val_loss: 2.6038 - val_precision: 0.2209\n",
      "Epoch 157/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5194 - precision: 0.9084 - val_loss: 2.6254 - val_precision: 0.2118\n",
      "Epoch 158/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4977 - precision: 0.9078 - val_loss: 2.6207 - val_precision: 0.2138\n",
      "Epoch 159/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5189 - precision: 0.9108 - val_loss: 2.6158 - val_precision: 0.2059\n",
      "Epoch 160/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5044 - precision: 0.9038 - val_loss: 2.6238 - val_precision: 0.2023\n",
      "Epoch 161/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4985 - precision: 0.8993 - val_loss: 2.6205 - val_precision: 0.2024\n",
      "Epoch 162/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5044 - precision: 0.9033 - val_loss: 2.6454 - val_precision: 0.2164\n",
      "Epoch 163/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4890 - precision: 0.9048 - val_loss: 2.6297 - val_precision: 0.2131\n",
      "Epoch 164/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.5045 - precision: 0.9001 - val_loss: 2.6300 - val_precision: 0.2065\n",
      "Epoch 165/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4847 - precision: 0.9067 - val_loss: 2.6334 - val_precision: 0.2204\n",
      "Epoch 166/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4777 - precision: 0.9075 - val_loss: 2.6356 - val_precision: 0.2139\n",
      "Epoch 167/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4762 - precision: 0.9002 - val_loss: 2.6344 - val_precision: 0.1907\n",
      "Epoch 168/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4747 - precision: 0.9001 - val_loss: 2.6316 - val_precision: 0.2011\n",
      "Epoch 169/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4799 - precision: 0.9051 - val_loss: 2.6419 - val_precision: 0.2083\n",
      "Epoch 170/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4746 - precision: 0.9048 - val_loss: 2.6430 - val_precision: 0.2124\n",
      "Epoch 171/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4883 - precision: 0.9025 - val_loss: 2.6458 - val_precision: 0.2124\n",
      "Epoch 172/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4695 - precision: 0.9005 - val_loss: 2.6493 - val_precision: 0.1818\n",
      "Epoch 173/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4535 - precision: 0.8994 - val_loss: 2.6644 - val_precision: 0.1990\n",
      "Epoch 174/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4657 - precision: 0.9025 - val_loss: 2.6689 - val_precision: 0.1980\n",
      "Epoch 175/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4690 - precision: 0.9094 - val_loss: 2.6620 - val_precision: 0.2010\n",
      "Epoch 176/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4556 - precision: 0.9076 - val_loss: 2.6635 - val_precision: 0.1893\n",
      "Epoch 177/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.4552 - precision: 0.9007 - val_loss: 2.6696 - val_precision: 0.1971\n",
      "Epoch 178/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4424 - precision: 0.9072 - val_loss: 2.6775 - val_precision: 0.1934\n",
      "Epoch 179/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4665 - precision: 0.9044 - val_loss: 2.6604 - val_precision: 0.2037\n",
      "Epoch 180/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4385 - precision: 0.9036 - val_loss: 2.6747 - val_precision: 0.2133\n",
      "Epoch 181/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4357 - precision: 0.9050 - val_loss: 2.6760 - val_precision: 0.1928\n",
      "Epoch 182/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4381 - precision: 0.9059 - val_loss: 2.6933 - val_precision: 0.2146\n",
      "Epoch 183/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4351 - precision: 0.9052 - val_loss: 2.7013 - val_precision: 0.2182\n",
      "Epoch 184/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4385 - precision: 0.9076 - val_loss: 2.6788 - val_precision: 0.2089\n",
      "Epoch 185/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4215 - precision: 0.9071 - val_loss: 2.6798 - val_precision: 0.2123\n",
      "Epoch 186/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4335 - precision: 0.9057 - val_loss: 2.6743 - val_precision: 0.2123\n",
      "Epoch 187/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4157 - precision: 0.9040 - val_loss: 2.6898 - val_precision: 0.2089\n",
      "Epoch 188/200\n",
      "11/11 [==============================] - 0s 5ms/step - loss: 1.4171 - precision: 0.9055 - val_loss: 2.6928 - val_precision: 0.1975\n",
      "Epoch 189/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4249 - precision: 0.9044 - val_loss: 2.6950 - val_precision: 0.2061\n",
      "Epoch 190/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4248 - precision: 0.9052 - val_loss: 2.7015 - val_precision: 0.2009\n",
      "Epoch 191/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4010 - precision: 0.9051 - val_loss: 2.6858 - val_precision: 0.1930\n",
      "Epoch 192/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4138 - precision: 0.9070 - val_loss: 2.7132 - val_precision: 0.1957\n",
      "Epoch 193/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4161 - precision: 0.9085 - val_loss: 2.6923 - val_precision: 0.1923\n",
      "Epoch 194/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4032 - precision: 0.9064 - val_loss: 2.6993 - val_precision: 0.1931\n",
      "Epoch 195/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.4109 - precision: 0.9061 - val_loss: 2.7160 - val_precision: 0.1923\n",
      "Epoch 196/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.3942 - precision: 0.9100 - val_loss: 2.7134 - val_precision: 0.2000\n",
      "Epoch 197/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.3905 - precision: 0.9080 - val_loss: 2.7248 - val_precision: 0.1885\n",
      "Epoch 198/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.3997 - precision: 0.9056 - val_loss: 2.7176 - val_precision: 0.1815\n",
      "Epoch 199/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.3907 - precision: 0.9061 - val_loss: 2.7532 - val_precision: 0.1937\n",
      "Epoch 200/200\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.3962 - precision: 0.9059 - val_loss: 2.7319 - val_precision: 0.1914\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\n",
    "train_dataset = dataset.shuffle(len(X_train)).batch(500)\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))\n",
    "validation_dataset = dataset.shuffle(len(X_test)).batch(500)\n",
    "\n",
    "print(\"Start training..\\n\")\n",
    "history = model.fit(train_dataset, epochs=200, validation_data=validation_dataset)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision = history.history['precision']\n",
    "val_precision = history.history['val_precision']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(precision) + 1)\n",
    "\n",
    "plt.plot(epochs, precision, 'b', label='Training precision')\n",
    "plt.plot(epochs, val_precision, 'r', label='Validation precision')\n",
    "plt.title('Training and validation precision')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_precision' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a9383e21f56d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_precision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'val_precision' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "With the 2 layer nerual network, we reached 0.92 precision on the the training dataset. However, best precision on the testing dataset was about 0.3, which happened around epoch 70~80. Then overfitting happened. \n",
    "\n",
    "precision = 0.3, means If we bet 'Win' 10 times based on the model's prediction, only 3 times is correct.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
